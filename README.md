# spark_parallel_processing
Even though spark is a parallel procesing engine there are some operartions which are still executed sequentially
So I have used threadpool of python multiprocessing to run independent process seperately
