# spark_parallel_processing
Even though spark is a parallel procesing engine there is still a sequential operation 
So I have used threadpool of python multiprocessing to run independent process seperately
